{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d56eba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cedc806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"Compute the sigmoid function.\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def logistic_regression(X, y, num_iterations, learning_rate):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model on the given dataset.\n",
    "\n",
    "    Args:\n",
    "        X: A numpy array of shape (m, n) containing the input features.\n",
    "        y: A numpy array of shape (m, 1) containing the target labels.\n",
    "        num_iterations: An integer specifying the number of iterations to run gradient descent.\n",
    "        learning_rate: A float specifying the learning rate for gradient descent.\n",
    "\n",
    "    Returns:\n",
    "        w: A numpy array of shape (n, 1) containing the learned weights.\n",
    "        b: A float containing the learned bias term.\n",
    "    \"\"\"\n",
    "    # Initialize the parameters\n",
    "    m, n = X.shape\n",
    "    w = np.zeros((n, 1))\n",
    "    b = 0\n",
    "\n",
    "    # Run gradient descent\n",
    "    for i in range(num_iterations):\n",
    "        # Forward propagation\n",
    "        z = np.dot(X, w) + b\n",
    "        a = sigmoid(z)\n",
    "\n",
    "        # Compute the cost function\n",
    "        cost = (-1 / m) * np.sum(y * np.log(a) + (1 - y) * np.log(1 - a))\n",
    "    \n",
    "        # Backward propagation\n",
    "        dz = a - y\n",
    "        dw = (1 / m) * np.dot(X.T, dz)\n",
    "        db = (1 / m) * np.sum(dz)\n",
    "\n",
    "        # Update the parameters\n",
    "        w = w - learning_rate * dw\n",
    "        b =b - learning_rate * db\n",
    "\n",
    "    return w, b\n",
    "\n",
    "\n",
    "def predict(X,y,w, b):\n",
    "    \"\"\"\n",
    "    Predict the target labels for a given set of input features using the learned weights and bias.\n",
    "\n",
    "    Args:\n",
    "        X: A numpy array of shape (m, n) containing the input features.\n",
    "        w: A numpy array of shape (n, 1) containing the learned weights.\n",
    "        b: A float containing the learned bias term.\n",
    "\n",
    "    Returns:\n",
    "        y_pred: A numpy array of shape (m, 1) containing the predicted target labels.\n",
    "    \"\"\"\n",
    "    # Compute the linear combination of the input features and the learned weights\n",
    "    z = np.dot(X, w) + b\n",
    "\n",
    "    # Compute the sigmoid of z\n",
    "    a = sigmoid(z)\n",
    "\n",
    "    # Threshold the predicted values at 0.5\n",
    "    y_pred = (a >= 0.5).astype(int)\n",
    "    accuracy = np.mean(y_pred == y)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def accuracy(tp, tn, fp, fn):\n",
    "    return (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "def precision(tp, tn, fp, fn):\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(tp, tn, fp, fn):\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def f1_score(p,r):\n",
    "    return 2 * (p * r) / (p + r)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0699c6",
   "metadata": {},
   "source": [
    "3A.Design a Logistic Regression model to predict whether a student reported flu-like\n",
    "symptoms in the past year i.e., Flu(y) using below 12 variables in the dataset as input\n",
    "variables:\n",
    "Vaccin, HndWshQual, HndWshFreq, SociDist, NoFaceContact, RespEttiqu, PersnDist,\n",
    "HandSanit, Risk, Inefficacy, KnowlTrans, KnowlMgmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c6cb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Flu dataset\n",
    "df = pd.read_csv('flu_data.csv')\n",
    "df.dropna(inplace=True)\n",
    "#X= df[['Risk']]\n",
    "X= df[['Vaccin','HndWshQual','HndWshFreq','SociDist','NoFaceContact','RespEttiqu','PersnDist','HandSanit','Risk','Inefficacy','KnowlTrans','KnowlMgmt']].to_numpy()\n",
    "y=df[['Flu']].to_numpy()\n",
    "#fit logistic regression model to data\n",
    "w,b= logistic_regression(X, y, num_iterations=3000, learning_rate=0.1)\n",
    "accuracy=predict(X,y,w,b)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca7635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f46b252",
   "metadata": {},
   "source": [
    "3B.Design a Logistic Regression model to predict whether a student reported flu-like\n",
    "symptoms in the past year i.e., Flu(y) using forward selection to select most significant\n",
    "variables in the dataset as input variables. Which subset of features gave you the best\n",
    "performance? What are your thoughts on these features getting selected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8e55b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(X, y, num_iterations, learning_rate):\n",
    "    \"\"\"\n",
    "    Perform forward selection to select the most significant features for logistic regression.\n",
    "\n",
    "    Args:\n",
    "        X: A numpy array of shape (m, n) containing the input features.\n",
    "        y: A numpy array of shape (m, 1) containing the target labels.\n",
    "        num_iterations: An integer specifying the number of iterations to run gradient descent.\n",
    "        learning_rate: A float specifying the learning rate for gradient descent.\n",
    "\n",
    "    Returns:\n",
    "        selected_features: A list of the most significant features selected by forward selection.\n",
    "    \"\"\"\n",
    "    # Initialize the list of selected features and remaining features\n",
    "    m, n = X.shape\n",
    "    selected_features = []\n",
    "    remaining_features = list(range(n))\n",
    "\n",
    "    # Run forward selection\n",
    "    for i in range(n):\n",
    "        best_feature = None\n",
    "        best_score = float('-inf')\n",
    "\n",
    "        # Evaluate each remaining feature\n",
    "        for j in remaining_features:\n",
    "            # Train a logistic regression model with the selected features and the j-th feature\n",
    "            features = selected_features + [j]\n",
    "            X_train = X[:, features]\n",
    "            w, b = logistic_regression(X_train, y, num_iterations, learning_rate)\n",
    "\n",
    "            # Compute the accuracy of the model using cross-validation or a holdout set\n",
    "            # Here, we'll just compute the accuracy on the training set for simplicity\n",
    "            z = np.dot(X_train, w) + b\n",
    "            predictions = sigmoid(z) >= 0.5\n",
    "            accuracy = np.mean(predictions == y)\n",
    "        \n",
    "            # If the accuracy is better than the current best, update the best feature\n",
    "            if accuracy > best_score:\n",
    "                best_feature = j\n",
    "                best_score = accuracy\n",
    "                \n",
    "        # Add the best feature to the selected features and remove it from the remaining features\n",
    "        selected_features.append(best_feature)\n",
    "        remaining_features.remove(best_feature)\n",
    "        print(selected_features)\n",
    "        print(best_score)\n",
    "    return selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f6f79ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "0.8148148148148148\n",
      "[0, 1]\n",
      "0.8233618233618234\n",
      "[0, 1, 2]\n",
      "0.8262108262108262\n",
      "[0, 1, 2, 3]\n",
      "0.8262108262108262\n",
      "[0, 1, 2, 3, 4]\n",
      "0.8262108262108262\n",
      "[0, 1, 2, 3, 4, 5]\n",
      "0.8262108262108262\n",
      "[0, 1, 2, 3, 4, 5, 6]\n",
      "0.8290598290598291\n",
      "[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "0.8319088319088319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('flu_data.csv')\n",
    "df.dropna(inplace=True)\n",
    "#X= df[['Risk']].to_numpy()\n",
    "X= df[['Risk','HandSanit','HndWshFreq','SociDist','KnowlTrans','Vaccin','RespEttiqu','Inefficacy']].to_numpy()\n",
    "y=df[['Flu']].to_numpy()\n",
    "forward_selection(X,y,3000,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa897bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da1870b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e3c11a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
