{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09200dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01091ea",
   "metadata": {},
   "source": [
    "4A.i For the best performing model in Q 3 (Model from 3c), does regularization improve\n",
    "the performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "887e4de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"Compute the sigmoid function.\"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def logistic_regression_with_regularization(X, y, num_iterations, learning_rate,lambd):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model on the given dataset.\n",
    "\n",
    "    Args:\n",
    "        X: A numpy array of shape (m, n) containing the input features.\n",
    "        y: A numpy array of shape (m, 1) containing the target labels.\n",
    "        num_iterations: An integer specifying the number of iterations to run gradient descent.\n",
    "        learning_rate: A float specifying the learning rate for gradient descent.\n",
    "\n",
    "    Returns:\n",
    "        w: A numpy array of shape (n, 1) containing the learned weights.\n",
    "        b: A float containing the learned bias term.\n",
    "    \"\"\"\n",
    "    # Initialize the parameters\n",
    "    m, n = X.shape\n",
    "    w = np.zeros((n, 1))\n",
    "    b = 0\n",
    "\n",
    "    # Run gradient descent\n",
    "    for i in range(num_iterations):\n",
    "        # Forward propagation\n",
    "        z = np.dot(X, w) + b\n",
    "        a = sigmoid(z)\n",
    "\n",
    "        # Compute the cost function with regularization\n",
    "        cost = (-1 / m) * np.sum(y * np.log(a) + (1 - y) * np.log(1 - a)) + (lambd / (2 * m)) * np.sum(w ** 2)\n",
    "\n",
    "        # Backward propagation\n",
    "        dz = a - y\n",
    "        dw = (1 / m) * np.dot(X.T, dz)\n",
    "        db = (1 / m) * np.sum(dz)\n",
    "\n",
    "        # Update the parameters\n",
    "        w = w - learning_rate * dw\n",
    "        b =b - learning_rate * db\n",
    "\n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f364647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,y,w, b):\n",
    "    \"\"\"\n",
    "    Predict the target labels for a given set of input features using the learned weights and bias.\n",
    "\n",
    "    Args:\n",
    "        X: A numpy array of shape (m, n) containing the input features.\n",
    "        w: A numpy array of shape (n, 1) containing the learned weights.\n",
    "        b: A float containing the learned bias term.\n",
    "\n",
    "    Returns:\n",
    "        y_pred: A numpy array of shape (m, 1) containing the predicted target labels.\n",
    "    \"\"\"\n",
    "    # Compute the linear combination of the input features and the learned weights\n",
    "    z = np.dot(X, w) + b\n",
    "\n",
    "    # Compute the sigmoid of z\n",
    "    a = sigmoid(z)\n",
    "\n",
    "    # Threshold the predicted values at 0.5\n",
    "    y_pred = (a >= 0.5).astype(int)\n",
    "    accuracy = np.mean(y_pred == y)\n",
    "\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d61f049f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8319088319088319\n"
     ]
    }
   ],
   "source": [
    "# Read the Flu dataset\n",
    "df = pd.read_csv('flu_data.csv')\n",
    "df.dropna(inplace=True)\n",
    "#X= df[['Vaccin','HndWshQual','HndWshFreq','SociDist','NoFaceContact','RespEttiqu','PersnDist','HandSanit','Risk','Inefficacy','KnowlTrans','KnowlMgmt']].to_numpy()\n",
    "X= df[['Risk','HandSanit','HndWshFreq','SociDist','KnowlTrans','Vaccin','RespEttiqu','Inefficacy']].to_numpy()\n",
    "\n",
    "y=df[['Flu']].to_numpy()\n",
    "#fit logistic regression model to data\n",
    "w,b= logistic_regression_with_regularization(X, y, num_iterations=3000, learning_rate=0.1,lambd=100)\n",
    "accuracy=predict(X,y,w,b)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe0b344",
   "metadata": {},
   "source": [
    "4A. ii Does Feature Scaling improve the performance for the model in Q 4a?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d288ccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X):\n",
    "    \"\"\"\n",
    "    Standardize the input features using standardization.\n",
    "\n",
    "    Args:\n",
    "        X: A numpy array of shape (m, n) containing the input features.\n",
    "\n",
    "    Returns:\n",
    "        X_std: A numpy array of shape (m, n) containing the standardized input features.\n",
    "        mean: A numpy array of shape (1, n) containing the mean of each input feature.\n",
    "        std: A numpy array of shape (1, n) containing the standard deviation of each input feature.\n",
    "    \"\"\"\n",
    "    # Compute the mean and standard deviation of each feature\n",
    "    mean = np.mean(X, axis=0)\n",
    "    std = np.std(X, axis=0)\n",
    "\n",
    "    # Standardize the features\n",
    "    X_std = (X - mean) / std\n",
    "\n",
    "    return X_std, mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb96f164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8233618233618234\n"
     ]
    }
   ],
   "source": [
    "# Read the Flu dataset\n",
    "df = pd.read_csv('flu_data.csv')\n",
    "df.dropna(inplace=True)\n",
    "#X= df[['Vaccin','HndWshQual','HndWshFreq','SociDist','NoFaceContact','RespEttiqu','PersnDist','HandSanit','Risk','Inefficacy','KnowlTrans','KnowlMgmt']].to_numpy()\n",
    "X= df[['Risk','HandSanit','HndWshFreq','SociDist','KnowlTrans','Vaccin','RespEttiqu','Inefficacy']].to_numpy()\n",
    "X,mean,std = standardize(X)\n",
    "y=df[['Flu']].to_numpy()\n",
    "#fit logistic regression model to data\n",
    "w,b= logistic_regression_with_regularization(X, y, num_iterations=3000, learning_rate=0.1,lambd=100)\n",
    "accuracy=predict(X,y,w,b)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdc6c42",
   "metadata": {},
   "source": [
    "4B.i Keeping the best regularized (or not) model after the experiments from 4a, design\n",
    "a Logistic Regression model to predict whether a student reported flu-like\n",
    "symptoms in the past year i.e., Flu(y) by changing the cost function to the\n",
    "following.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0f4435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_with_new_cf(X, y, num_iterations, learning_rate):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model on the given dataset.\n",
    "\n",
    "    Args:\n",
    "        X: A numpy array of shape (m, n) containing the input features.\n",
    "        y: A numpy array of shape (m, 1) containing the target labels.\n",
    "        num_iterations: An integer specifying the number of iterations to run gradient descent.\n",
    "        learning_rate: A float specifying the learning rate for gradient descent.\n",
    "\n",
    "    Returns:\n",
    "        w: A numpy array of shape (n, 1) containing the learned weights.\n",
    "        b: A float containing the learned bias term.\n",
    "    \"\"\"\n",
    "    # Initialize the parameters\n",
    "    m, n = X.shape\n",
    "    w = np.zeros((n, 1))\n",
    "    b = 0\n",
    "\n",
    "    # Run gradient descent\n",
    "    for i in range(num_iterations):\n",
    "        # Forward propagation\n",
    "        z = np.dot(X, w) + b\n",
    "        a = sigmoid(z)\n",
    "\n",
    "        # Compute the cost function with regularization\n",
    "        cost = (1 / (2 * m)) * np.sum((a - y) ** 2)\n",
    "\n",
    "        # Backward propagation\n",
    "        dz = a - y\n",
    "        dw = (1 / m) * np.dot(X.T, dz)\n",
    "        db = (1 / m) * np.sum(dz)\n",
    "\n",
    "        # Update the parameters\n",
    "        w = w - learning_rate * dw\n",
    "        b =b - learning_rate * db\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24077555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8319088319088319\n"
     ]
    }
   ],
   "source": [
    "# Read the Flu dataset\n",
    "df = pd.read_csv('flu_data.csv')\n",
    "df.dropna(inplace=True)\n",
    "#X= df[['Vaccin','HndWshQual','HndWshFreq','SociDist','NoFaceContact','RespEttiqu','PersnDist','HandSanit','Risk','Inefficacy','KnowlTrans','KnowlMgmt']].to_numpy()\n",
    "X= df[['Risk','HandSanit','HndWshFreq','SociDist','KnowlTrans','Vaccin','RespEttiqu','Inefficacy']].to_numpy()\n",
    "y=df[['Flu']].to_numpy()\n",
    "#fit logistic regression model to data\n",
    "w,b= logistic_regression_with_new_cf(X, y, num_iterations=3000, learning_rate=0.1)\n",
    "accuracy=predict(X,y,w,b)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e6c7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
